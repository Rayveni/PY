{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilya.Volchkov\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:161: UserWarning: pylab import has clobbered these variables: ['product', 'datetime']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "from itertools import product,combinations\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from datetime import timedelta,datetime, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor,ExtraTreesRegressor\n",
    "from sklearn.metrics import r2_score,make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Если загрузка данных из csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path=r\"C:\\Reports\\FC\"\n",
    "store_detail=True\n",
    "data = pd.read_csv(os.path.join(path,'total_sales_day.csv'),';', index_col=['day'], parse_dates=['day'], dayfirst=True)\n",
    "data=data.ix[:,:3]\n",
    "data=pd.read_excel(os.path.join(path,'total_sales.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Если загрузка данных из excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>filial</th>\n",
       "      <th>day</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Филиал Средне-Волжск</td>\n",
       "      <td>01.01.2014</td>\n",
       "      <td>994,718.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>Филиал Средне-Волжск</td>\n",
       "      <td>02.01.2014</td>\n",
       "      <td>2,082,729.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>Филиал Средне-Волжск</td>\n",
       "      <td>03.01.2014</td>\n",
       "      <td>2,159,405.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store                filial         day         sales\n",
       "0   1001  Филиал Средне-Волжск  01.01.2014    994,718.85\n",
       "1   1001  Филиал Средне-Волжск  02.01.2014  2,082,729.68\n",
       "2   1001  Филиал Средне-Волжск  03.01.2014  2,159,405.64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=r\"C:\\Reports\\FC\"\n",
    "store_detail=True\n",
    "data = pd.read_csv(os.path.join(path,'total_sales_new.csv'),',', dayfirst=True,encoding='cp1251')\n",
    "data.columns=['store','filial','day','sales']\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['day']=pd.to_datetime(data.day,dayfirst=True)\n",
    "data.set_index(['day'],inplace=True)\n",
    "data['sales']=data['sales'].apply(lambda x:np.float(str(x).replace(',','')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Флаг детализации по магазинам\n",
    "если не требуется, запускаем ячейку ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)\n",
    "data=data.pivot_table(index=['day'],aggfunc=np.sum)\n",
    "data['store']=1\n",
    "data['filial']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 168 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "moving_week_window=3\n",
    "moving_month_window=3\n",
    "\n",
    "min_date=min(data.index)\n",
    "def extract_date(df):\n",
    "    df.is_a_copy=False\n",
    "    df['day_of_week']=df.index.dayofweek\n",
    "    df['month']=df.index.month\n",
    "    df['total_days']=(df.index-min_date).days\n",
    "    df['num_day']=df.index.day\n",
    "    df['month_part']=df.num_day.apply(lambda x:x//8 )\n",
    "    df['week_num']=df.index.week\n",
    "\n",
    "    for i in range(1,moving_week_window+3):\n",
    "        df[str(i)+'_week_before']=df.index-timedelta(days=7*i)\n",
    "    df['date_withot_day']=[df.index[i]-timedelta(days=int(df.num_day.values[i]-1))  for i in range(df.shape[0])]\n",
    "    for i in range(1,moving_month_window+3):\n",
    "        df[str(i)+'_month_before']=df['date_withot_day'].apply(lambda x:x-relativedelta(months=+1*i))\n",
    "    return df\n",
    "def find_in_agg_df(df,pattern):\n",
    "    try:\n",
    "        r=df.ix[tuple(pattern)]['sales']\n",
    "        #print(r)\n",
    "    except:r=np.nan\n",
    "    try:    \n",
    "        r=r.values[0]\n",
    "    except:pass\n",
    "    return r\n",
    "def calc_prev_month(df):\n",
    "    agg_month=df[['date_withot_day','sales','store']].pivot_table(index=['date_withot_day','store'],aggfunc=np.sum)\n",
    "    for i in range(1,moving_month_window+3):\n",
    "        column_name=str(i)+'_month_before'\n",
    "        df[column_name]=df[[column_name,'store']].apply(lambda row:find_in_agg_df(agg_month,row),axis=1)\n",
    "    return df\n",
    "def create_moving_week(df):\n",
    "    df.reset_index(inplace=True)\n",
    "    start_date=min_date+timedelta(days=6)\n",
    "    res=df[df['day']>start_date][['day','store','1_week_before']].reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    res['sales']=res.apply(lambda row:np.sum(df[(df['store']==row['store'])&\n",
    "                                         (df['day']>=row['1_week_before'])&\n",
    "                                         (df['day']<row['day'])]['sales']),axis=1)\n",
    "    \n",
    "    res.drop('1_week_before',axis=1,inplace=True)\n",
    " \n",
    "    res.sort_values(by=['day','store'],inplace=True)\n",
    "\n",
    "    \n",
    "    res.set_index(['day', 'store'],inplace=True)\n",
    "    return res\n",
    "\n",
    "def apply_moving_week_month(df):\n",
    "    df.is_a_copy=False\n",
    "    agg_week_df=create_moving_week(df)\n",
    "\n",
    "    for i in range(1,moving_week_window+3):\n",
    "        column_name=str(i)+'_week_before'\n",
    "        df[column_name]=df[[column_name,'store']].apply(lambda row:find_in_agg_df(agg_week_df,row),axis=1)\n",
    "        print(column_name)\n",
    "   \n",
    "    df.dropna(inplace=True)\n",
    "    # print(df.shape)\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    #return agg_week_df,df\n",
    "    for i in range(1,moving_week_window+1):\n",
    "    \n",
    "        column_names=[str(x)+'_week_before' for x in range(i,i+3) ]\n",
    "        column_name_new=str(i)+'avg_week'\n",
    "        df[column_name_new]=df[column_names].apply(np.mean,axis=1)\n",
    "    for i in range(1,moving_month_window+1):\n",
    "        column_names=[str(x)+'_month_before' for x in range(i,i+3) ]\n",
    "        column_name_new=str(i)+'avg_month'\n",
    "        df[column_name_new]=df[column_names].apply(np.mean,axis=1)\n",
    "\n",
    "    columns=[str(x)+'_week_before' for x in range(1,moving_week_window+3)]+[\n",
    "        str(x)+'_month_before' for x in range(1,moving_month_window+3)]\n",
    "    df.drop(columns,axis=1,inplace=True)\n",
    "    return df\n",
    "def generate_features(df,columns,degree,suffix):\n",
    "    polynom_arr=PolynomialFeatures(degree).fit_transform(df[columns])\n",
    "    polynom_df=pd.DataFrame(polynom_arr,columns=[str(el )+suffix for el in range(polynom_arr.shape[1])])\n",
    "    \n",
    "    for comb in combinations(range(len(columns)),2):\n",
    "    \n",
    "        polynom_df[suffix+columns[comb[0]]+'+'+columns[comb[1]]]=df[columns[comb[0]]]+df[columns[comb[1]]]\n",
    "\n",
    "        polynom_df[suffix+columns[comb[0]]+'-'+columns[comb[1]]]=df[columns[comb[0]]]-df[columns[comb[1]]]\n",
    "        polynom_df[suffix+columns[comb[0]]+'/'+columns[comb[1]]]=df[columns[comb[0]]]/df[columns[comb[1]]]\n",
    "        polynom_df[suffix+columns[comb[0]]+'*'+columns[comb[1]]]=df[columns[comb[0]]]*df[columns[comb[1]]]\n",
    "        \n",
    "    return polynom_df\n",
    "\n",
    "\n",
    "def transform(df,real_columns,cat_columns):\n",
    "    df.is_a_copy=False\n",
    "\n",
    "    df_real=df[real_columns]\n",
    "    scaler = StandardScaler()\n",
    "    df_real=pd.DataFrame(scaler.fit_transform(df_real),columns=real_columns)\n",
    "    res=[df_real]\n",
    "    df_cat=df[cat_columns]\n",
    "    for column in df_cat.columns.values:\n",
    "        data_slice=df_cat[column].astype(str)\n",
    "        res.append(pd.get_dummies(data_slice,prefix =column, dummy_na=False))        \n",
    "    res=pd.concat(res,axis=1)\n",
    "    return res\n",
    "def final_prepare_data(df):\n",
    "    avg_month_cols=[str(i)+'avg_month' for i in range(1,moving_month_window+1)]\n",
    "    avg_week_cols=[str(i)+'avg_week' for i in range(1,moving_week_window+1)]\n",
    "    multiple_df=pd.concat([generate_features(df,avg_month_cols,2,'month'),\n",
    "                generate_features(df,avg_week_cols,2,'week')],axis=1)\n",
    "    avg_month_cols=[str(i)+'avg_month' for i in range(1,moving_month_window+1)]\n",
    "    avg_week_cols=[str(i)+'avg_week' for i in range(1,moving_week_window+1)]\n",
    "\n",
    "    real_features=['sales','total_days']+list(multiple_df.columns.values)#+avg_month_cols+avg_week_cols\n",
    "    cat_features=['filial','store','day_of_week', 'month', 'month_part','week_num']\n",
    "    \n",
    "    res=pd.concat([df,multiple_df],axis=1)\n",
    "    res.drop(avg_month_cols+avg_week_cols,inplace=True,axis=1)\n",
    "    \n",
    "    res=transform(res,real_features,cat_features)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Готовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_week_before\n",
      "2_week_before\n",
      "3_week_before\n",
      "4_week_before\n",
      "5_week_before\n",
      "Wall time: 17min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# извлекаем  части дат из данных\n",
    "data=extract_date(data)\n",
    "# добавляем данные за пред месяцы \n",
    "data=calc_prev_month(data)\n",
    "# добавляем данные за пред недели\n",
    "data=apply_moving_week_month(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day', 'store', 'filial', 'sales', 'day_of_week', 'month', 'total_days',\n",
       "       'num_day', 'month_part', 'week_num', 'date_withot_day', '1avg_week',\n",
       "       '2avg_week', '3avg_week', '1avg_month', '2avg_month', '3avg_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>store</th>\n",
       "      <th>filial</th>\n",
       "      <th>sales</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>total_days</th>\n",
       "      <th>num_day</th>\n",
       "      <th>month_part</th>\n",
       "      <th>week_num</th>\n",
       "      <th>date_withot_day</th>\n",
       "      <th>1avg_week</th>\n",
       "      <th>2avg_week</th>\n",
       "      <th>3avg_week</th>\n",
       "      <th>1avg_month</th>\n",
       "      <th>2avg_month</th>\n",
       "      <th>3avg_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>1001</td>\n",
       "      <td>Филиал Средне-Волжск</td>\n",
       "      <td>1897393.15</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>1.316681e+07</td>\n",
       "      <td>1.371408e+07</td>\n",
       "      <td>1.363993e+07</td>\n",
       "      <td>60963675.9</td>\n",
       "      <td>6.043963e+07</td>\n",
       "      <td>6.027191e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-06-02</td>\n",
       "      <td>1001</td>\n",
       "      <td>Филиал Средне-Волжск</td>\n",
       "      <td>1652624.08</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>1.320715e+07</td>\n",
       "      <td>1.364427e+07</td>\n",
       "      <td>1.367672e+07</td>\n",
       "      <td>60963675.9</td>\n",
       "      <td>6.043963e+07</td>\n",
       "      <td>6.027191e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-06-03</td>\n",
       "      <td>1001</td>\n",
       "      <td>Филиал Средне-Волжск</td>\n",
       "      <td>1543799.17</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>153</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>1.319746e+07</td>\n",
       "      <td>1.359068e+07</td>\n",
       "      <td>1.374656e+07</td>\n",
       "      <td>60963675.9</td>\n",
       "      <td>6.043963e+07</td>\n",
       "      <td>6.027191e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         day  store                filial       sales  day_of_week  month  \\\n",
       "0 2014-06-01   1001  Филиал Средне-Волжск  1897393.15            6      6   \n",
       "1 2014-06-02   1001  Филиал Средне-Волжск  1652624.08            0      6   \n",
       "2 2014-06-03   1001  Филиал Средне-Волжск  1543799.17            1      6   \n",
       "\n",
       "   total_days  num_day  month_part  week_num date_withot_day     1avg_week  \\\n",
       "0         151        1           0        22      2014-06-01  1.316681e+07   \n",
       "1         152        2           0        23      2014-06-01  1.320715e+07   \n",
       "2         153        3           0        23      2014-06-01  1.319746e+07   \n",
       "\n",
       "      2avg_week     3avg_week  1avg_month    2avg_month    3avg_month  \n",
       "0  1.371408e+07  1.363993e+07  60963675.9  6.043963e+07  6.027191e+07  \n",
       "1  1.364427e+07  1.367672e+07  60963675.9  6.043963e+07  6.027191e+07  \n",
       "2  1.359068e+07  1.374656e+07  60963675.9  6.043963e+07  6.027191e+07  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#final_prepare_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(os.path.join(path,'data.csv'),sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строим прогноз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_date=max(data.day)\n",
    "\n",
    "def generate_day_df(df):\n",
    "    df.is_a_copy=False\n",
    "    start_date=max(df.day)\n",
    "    temp_df=df[df['day']>max_date-timedelta(days=(moving_month_window+2)*31)][['day','store','filial','sales']]\n",
    "    print(start_date)\n",
    "    res_df=temp_df[['store','filial']].drop_duplicates().reset_index(drop=True)\n",
    "    res_df['day']=start_date+timedelta(days=1)\n",
    "    res_df['sales']=0\n",
    "    res_df=pd.concat([temp_df,res_df],axis=0)\n",
    "    \n",
    "    #res_arr_element=[max_date+timedelta(days=1)]\n",
    "    \n",
    "    res_df.set_index(['day'],inplace=True)\n",
    "    res_df=extract_date(res_df)\n",
    "    #res_df.reset_index(inplace=True)\n",
    "    #res_df=pd.concat([temp_df,res_df],axis=0)\n",
    "    #\n",
    "    res_df=calc_prev_month(res_df)\n",
    "    \n",
    "    #res_df.drop('index',axis=1,inplace=True)\n",
    "    #res_df.set_index(['day'],inplace=True)\n",
    "    #return res_df\n",
    "    res_df=apply_moving_week_month(res_df)\n",
    "    #res_df.reset_index(inplace=True)\n",
    "    \n",
    "    res_df=res_df[res_df['day']>start_date].reset_index(drop=True)\n",
    "    \n",
    "    return res_df[data.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_data=final_prepare_data(data)\n",
    "cv_split_test=15\n",
    "n_folds=3\n",
    "max_day=max(data.day)\n",
    "train_index=data[data['day']<max_day-timedelta(days=cv_split_test*n_folds)].index\n",
    "X_train=merged_data.ix[train_index].drop('sales',axis=1)\n",
    "y_train=merged_data.ix[train_index]['sales'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myCViterator = []\n",
    "train_index=data[data['day']<max_day-timedelta(days=cv_split_test*n_folds)].index.values.astype(int)\n",
    "test_index=data[data['day']>=max_day-timedelta(days=cv_split_test*n_folds)].index.values.astype(int)\n",
    "for i in range(n_folds):\n",
    "    trainIndices = train_index\n",
    "    testIndices =  data[(data['day']>max_day-timedelta(days=cv_split_test*(i+1)))&\n",
    "                        (data['day']<=max_day-timedelta(days=cv_split_test*i))].index.values.astype(int)\n",
    "    myCViterator.append( (trainIndices, testIndices) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilya.Volchkov\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\ilya.Volchkov\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\ilya.Volchkov\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\ilya.Volchkov\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\ilya.Volchkov\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\ilya.Volchkov\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\ilya.Volchkov\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso 0.826652590278 {'alpha': 0.001}\n",
      "Ridge 0.826816512806 {'alpha': 1000.0}\n",
      "RandomForest 0.83901319528 {'min_samples_split': 2}\n",
      "ExtraTrees 0.867243696308 {'bootstrap': True}\n",
      "Wall time: 1h 44min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models=[('Lasso',Lasso(),{'alpha':np.power(10.0, np.arange(-5, 5))}),\n",
    "       ('Ridge',Ridge(),{'alpha':np.power(10.0, np.arange(-5, 5))}),\n",
    "       ('RandomForest',RandomForestRegressor(n_estimators=100),{'min_samples_split':[3,2]}),\n",
    "       ('ExtraTrees',ExtraTreesRegressor(n_estimators=100),{'bootstrap':[True,False] })]\n",
    "\n",
    "def create_ensemble(X,cv,models,test):\n",
    "    res=[]\n",
    "    for model in models:\n",
    "        X_train=X.drop('sales',axis=1)\n",
    "        y_train=X['sales'].values.ravel()\n",
    "        X_test=X.drop('sales',axis=1).ix[test]\n",
    "        gs=GridSearchCV(model[1],model[2],scoring= make_scorer(r2_score),cv=cv).fit(X_train,y_train)\n",
    "        best_score=gs.best_score_\n",
    "        print (model[0],best_score ,gs.best_params_)\n",
    "        res.append([gs.best_estimator_ ,best_score])\n",
    "    return res\n",
    "weighted_ensemble=create_ensemble(merged_data,myCViterator,models,test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#ensemble=[LinearRegression(),RandomForestRegressor(n_estimators=100)]\n",
    "#ensemble=[LinearRegression(),LinearRegression()]\n",
    "#ensemble=[RandomForestRegressor(n_estimators=50),RandomForestRegressor(n_estimators=50)]\n",
    "\n",
    "\n",
    "fitted_ensemble=lambda ensemble,data,target:[(model[0].fit(data,target),model[1]) for model in weighted_ensemble]\n",
    "#fitted_ensemble=lambda ensemble,data,target:[model.fit(data,target) for model in ensemble]\n",
    "#predict_ensemble=lambda fit_enseble,data:pd.DataFrame(\n",
    "#    np.array([model.predict(data) for model in fit_enseble]).T).apply(np.mean,axis=1).values\n",
    "predict_ensemble=lambda fit_enseble,data:pd.DataFrame(\n",
    "    np.array([model[1]*model[0].predict(data) for model in fit_enseble]).T).apply(np.sum,axis=1).values/np.sum([model[1] for model in fit_enseble])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilya.Volchkov\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_test=data.ix[test_index]['sales'].values.ravel()\n",
    "X_test=merged_data.ix[test_index].drop('sales',axis=1)\n",
    "X_train=merged_data.ix[trainIndices].drop('sales',axis=1)\n",
    "y_train=data.ix[trainIndices]['sales'].values.ravel()\n",
    "y_pred=predict_ensemble(fitted_ensemble(weighted_ensemble,X_train,y_train),X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forecast_day(df):\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    add_day=generate_day_df(df)\n",
    "\n",
    "\n",
    "    union_df_origin=pd.concat([df,add_day],axis=0).reset_index(drop=True)\n",
    "    union_df=final_prepare_data(union_df_origin)\n",
    "    \n",
    "    \n",
    "    train_data=union_df.ix[:df.shape[0]].drop('sales',axis=1)\n",
    "    y_train=union_df_origin.ix[:df.shape[0]]['sales'].values.ravel()\n",
    "\n",
    "    test_data=union_df.ix[df.shape[0]:].drop('sales',axis=1)\n",
    "    y_test=union_df_origin.ix[df.shape[0]:]['sales'].values.ravel() \n",
    "\n",
    "    \n",
    "    fitted_models=fitted_ensemble(ensemble,train_data,y_train)\n",
    "    y_pred=predict_ensemble(fitted_models,test_data)\n",
    "    add_day['sales']=y_pred\n",
    "    \n",
    "    \n",
    "    return add_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-28 00:00:00\n",
      "1_week_before\n",
      "2_week_before\n",
      "3_week_before\n",
      "4_week_before\n",
      "5_week_before\n",
      "(86, 17)\n",
      "204694565.7727001\n",
      "0\n",
      "2017-03-29 00:00:00\n",
      "1_week_before\n",
      "2_week_before\n",
      "3_week_before\n",
      "4_week_before\n",
      "5_week_before\n",
      "(86, 17)\n",
      "221693292.2447471\n",
      "1\n",
      "2017-03-30 00:00:00\n",
      "1_week_before\n",
      "2_week_before\n",
      "3_week_before\n",
      "4_week_before\n",
      "5_week_before\n",
      "(86, 17)\n",
      "295004251.66319996\n",
      "2\n",
      "2017-03-31 00:00:00\n",
      "1_week_before\n",
      "2_week_before\n",
      "3_week_before\n",
      "4_week_before\n",
      "5_week_before\n",
      "(86, 17)\n",
      "343068431.7875\n",
      "3\n",
      "2017-04-01 00:00:00\n",
      "1_week_before\n",
      "2_week_before\n",
      "3_week_before\n",
      "4_week_before\n",
      "5_week_before\n",
      "(86, 17)\n",
      "270010601.6885\n",
      "4\n",
      "2017-04-02 00:00:00\n",
      "1_week_before\n",
      "2_week_before\n",
      "3_week_before\n",
      "4_week_before\n",
      "5_week_before\n",
      "(86, 17)\n",
      "216674454.07349503\n",
      "5\n",
      "2017-04-03 00:00:00\n",
      "1_week_before\n",
      "2_week_before\n",
      "3_week_before\n",
      "4_week_before\n",
      "5_week_before\n",
      "(86, 17)\n",
      "212697725.74207166\n",
      "6\n",
      "2017-04-04 00:00:00\n",
      "1_week_before\n",
      "2_week_before\n",
      "3_week_before\n",
      "4_week_before\n",
      "5_week_before\n",
      "(86, 17)\n",
      "212861950.44738495\n",
      "7\n",
      "2017-04-05 00:00:00\n",
      "1_week_before\n",
      "2_week_before\n",
      "3_week_before\n",
      "4_week_before\n",
      "5_week_before\n",
      "(86, 17)\n",
      "234057649.04915082\n",
      "8\n",
      "2017-04-06 00:00:00\n",
      "1_week_before\n",
      "2_week_before\n",
      "3_week_before\n",
      "4_week_before\n",
      "5_week_before\n",
      "(86, 17)\n",
      "284915488.12572294\n",
      "9\n",
      "2017-04-07 00:00:00\n",
      "1_week_before\n",
      "2_week_before\n",
      "3_week_before\n",
      "4_week_before\n",
      "5_week_before\n",
      "(86, 17)\n",
      "312681533.861521\n",
      "10\n",
      "2017-04-08 00:00:00\n",
      "1_week_before\n",
      "2_week_before\n",
      "3_week_before\n",
      "4_week_before\n",
      "5_week_before\n",
      "(86, 17)\n",
      "249412143.6204641\n",
      "11\n",
      "2017-04-09 00:00:00\n",
      "1_week_before\n",
      "2_week_before\n",
      "3_week_before\n",
      "4_week_before\n",
      "5_week_before\n",
      "(86, 17)\n",
      "209799542.04403877\n",
      "12\n",
      "2017-04-10 00:00:00\n",
      "1_week_before\n",
      "2_week_before\n",
      "3_week_before\n",
      "4_week_before\n",
      "5_week_before\n",
      "(86, 17)\n",
      "209220516.44027182\n",
      "13\n",
      "Wall time: 3h 7min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def forecast_period(df,n_days=14):\n",
    "    df.is_a_copy=False\n",
    "    max_date=max(df.day)\n",
    "    for i in range(n_days):\n",
    "        add_day=forecast_day(df)\n",
    "        print(add_day.shape)\n",
    "        print(add_day.sales.sum())\n",
    "        df=pd.concat([df,add_day],axis=0).reset_index(drop=True)\n",
    "        print(i)\n",
    "        df.to_excel(os.path.join(path,'final_fc_ens.xlsx'),index=False)\n",
    "    return df\n",
    "forecast_df=forecast_period (data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forecast_df.to_excel(os.path.join(path,'fc_sales.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.path.join(path,'total_sales.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fitted_models=fitted_ensemble(ensemble,t[0],t[1])\n",
    "y_pred=predict_ensemble(fitted_models,t[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_ensemble(fitted_models,t[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fitted_models=fitted_ensemble(ensemble,X.drop('sales',axis=1),data['sales'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "t=generate_day_df(data)\n",
    "t.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max(t.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t[data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "multiple_df=pd.concat([generate_features(data,avg_month_cols,2,'month'),\n",
    "                generate_features(data,avg_week_cols,2,'week')],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_month_cols=[str(i)+'avg_month' for i in range(1,moving_month_window+1)]\n",
    "avg_week_cols=[str(i)+'avg_week' for i in range(1,moving_week_window+1)]\n",
    "\n",
    "real_features=['sales','total_days']+list(multiple_df.columns.values)#+avg_month_cols+avg_week_cols\n",
    "cat_features=['filial','store','day_of_week', 'month', 'month_part','week_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.concat([data,multiple_df],axis=1)\n",
    "data.drop(avg_month_cols+avg_week_cols,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X=transform(data,real_features,cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#year=data['day'].apply(lambda t:t.year)\n",
    "#train_index=year[year<2017].index\n",
    "#test_index=year[year>2016].index\n",
    "train_index=data[data['day']<date(2017, 3, 1)].index\n",
    "test_index=data[data['day']>=date(2017, 3, 1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data=X.ix[train_index].drop('sales',axis=1)\n",
    "y_train=data.ix[train_index]['sales'].values.ravel()\n",
    "test_data=X.ix[test_index].drop('sales',axis=1)\n",
    "y_test=data.ix[test_index]['sales'].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "lr=LinearRegression()\n",
    "rf=RandomForestRegressor(n_estimators=100)\n",
    "lr.fit(train_data,y_train)\n",
    "rf.fit(train_data,y_train)\n",
    "y_pred_lr=lr.predict(test_data)\n",
    "y_pred_rf=rf.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Финальный прогноз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble=[LinearRegression(),RandomForestRegressor(n_estimators=100)]\n",
    "fitted_ensemble=lambda ensemble,data,target:[model.fit(data,target) for model in ensemble]\n",
    "predict_ensemble=lambda fit_enseble,data:[model.predict(data) for model in fit_enseble].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitted_models=fitted_ensemble(ensemble,X.drop('sales',axis=1),data['sales'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t=pd.DataFrame(np.hstack([y_pred_rf.reshape(-1,1),y_pred_lr.reshape(-1,1)]),columns=['lr'])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_rf.sum(),y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(y_pred[10]-y_test[10])/y_test[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r2_score(y_test,y_pred_lr),r2_score(y_test,y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r2_score(y_test,y_pred_lr),r2_score(y_test,y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "((y_test+y_pred_rf)/2).sum(),y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize(15,7))\n",
    "data.sales.plot()\n",
    "#plt.ylabel(u'')\n",
    "#plt.title('')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
